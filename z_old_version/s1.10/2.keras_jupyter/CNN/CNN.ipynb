{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trains a simple convnet on the MNIST dataset.\n",
    "Gets to 99.25% test accuracy after 12 epochs\n",
    "(there is still a lot of margin for parameter tuning).\n",
    "16 seconds per epoch on a GRID K520 GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 112s 2ms/step - loss: 0.2506 - acc: 0.9235 - val_loss: 0.0540 - val_acc: 0.9821\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 120s 2ms/step - loss: 0.0862 - acc: 0.9744 - val_loss: 0.0408 - val_acc: 0.9868\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 125s 2ms/step - loss: 0.0666 - acc: 0.9800 - val_loss: 0.0361 - val_acc: 0.9884\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 142s 2ms/step - loss: 0.0547 - acc: 0.9838 - val_loss: 0.0334 - val_acc: 0.9891\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 196s 3ms/step - loss: 0.0468 - acc: 0.9852 - val_loss: 0.0335 - val_acc: 0.9890\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 107s 2ms/step - loss: 0.0412 - acc: 0.9874 - val_loss: 0.0305 - val_acc: 0.9896\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 114s 2ms/step - loss: 0.0373 - acc: 0.9886 - val_loss: 0.0320 - val_acc: 0.9897\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 118s 2ms/step - loss: 0.0328 - acc: 0.9895 - val_loss: 0.0276 - val_acc: 0.9912\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 123s 2ms/step - loss: 0.0303 - acc: 0.9912 - val_loss: 0.0268 - val_acc: 0.9915\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 115s 2ms/step - loss: 0.0271 - acc: 0.9914 - val_loss: 0.0274 - val_acc: 0.9904\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 104s 2ms/step - loss: 0.0271 - acc: 0.9915 - val_loss: 0.0304 - val_acc: 0.9912\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 166s 3ms/step - loss: 0.0284 - acc: 0.9911 - val_loss: 0.0306 - val_acc: 0.9903\n",
      "Test loss: 0.03063096653275188\n",
      "Test accuracy: 0.9903\n"
     ]
    }
   ],
   "source": [
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
